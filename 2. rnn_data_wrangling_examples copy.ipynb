{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data for a recurrent neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A recurrent neural network requires a 3D array as input. The first dimension is the number of samples, the second dimension is the number of time steps, and the third dimension is the number of features. The following code creates a 3D array with 3 samples, 2 time steps, and 1 feature.\n",
    "\n",
    "Let's say we want to predict the next day after sequence of 3 days.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to predict the next day after sequence of 3 days.  \n",
    "\n",
    "Here is the data we will use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temp</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-04-01</th>\n",
       "      <td>77</td>\n",
       "      <td>50</td>\n",
       "      <td>29.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-02</th>\n",
       "      <td>78</td>\n",
       "      <td>51</td>\n",
       "      <td>29.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03</th>\n",
       "      <td>79</td>\n",
       "      <td>52</td>\n",
       "      <td>29.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-04</th>\n",
       "      <td>80</td>\n",
       "      <td>53</td>\n",
       "      <td>29.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-05</th>\n",
       "      <td>78</td>\n",
       "      <td>67</td>\n",
       "      <td>29.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-06</th>\n",
       "      <td>82</td>\n",
       "      <td>59</td>\n",
       "      <td>29.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-07</th>\n",
       "      <td>76</td>\n",
       "      <td>58</td>\n",
       "      <td>29.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-08</th>\n",
       "      <td>76</td>\n",
       "      <td>56</td>\n",
       "      <td>29.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-09</th>\n",
       "      <td>85</td>\n",
       "      <td>62</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-10</th>\n",
       "      <td>73</td>\n",
       "      <td>55</td>\n",
       "      <td>30.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Temp  Humidity  Pressure\n",
       "2023-04-01    77        50     29.92\n",
       "2023-04-02    78        51     29.93\n",
       "2023-04-03    79        52     29.94\n",
       "2023-04-04    80        53     29.95\n",
       "2023-04-05    78        67     29.96\n",
       "2023-04-06    82        59     29.97\n",
       "2023-04-07    76        58     29.98\n",
       "2023-04-08    76        56     29.99\n",
       "2023-04-09    85        62     30.00\n",
       "2023-04-10    73        55     30.01"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    data={\n",
    "        'Temp':[77,78,79,80,78,82,76,76,85,73], \n",
    "        'Humidity': [50,51,52,53,67,59,58,56,62,55], \n",
    "        'Pressure': [29.92,29.93,29.94,29.95, 29.96,29.97,29.98,29.99,30.00,30.01]\n",
    "    }, \n",
    "    index=['2023-04-01','2023-04-02','2023-04-03','2023-04-04', '2023-04-05','2023-04-06','2023-04-07','2023-04-08','2023-04-09','2023-04-10'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the parameters of this problem we find that our first sample (observation) will be the feature values for the first 3 rows of the dataframe, and the second sample (observation) will be the next three rows starting at the second row, etc.\n",
    "\n",
    "Let's begin by converting the dataframe to a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[77.  , 50.  , 29.92],\n",
       "       [78.  , 51.  , 29.93],\n",
       "       [79.  , 52.  , 29.94],\n",
       "       [80.  , 53.  , 29.95],\n",
       "       [78.  , 67.  , 29.96],\n",
       "       [82.  , 59.  , 29.97],\n",
       "       [76.  , 58.  , 29.98],\n",
       "       [76.  , 56.  , 29.99],\n",
       "       [85.  , 62.  , 30.  ],\n",
       "       [73.  , 55.  , 30.01]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2D = df.to_numpy() # convert the dataframe to a numpy array\n",
    "arr2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2D data above is not not our input to the recurrent network - we have three feaures, but no observations. Observations will be the sequences length number of rows.\n",
    "\n",
    "This might be easier to understand if we look at how we can manually create observations for our recurrent network training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[77.  , 50.  , 29.92],\n",
       "       [78.  , 51.  , 29.93],\n",
       "       [79.  , 52.  , 29.94]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2D[0:3,:]  # this would be the first observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[78.  , 51.  , 29.93],\n",
       "       [79.  , 52.  , 29.94],\n",
       "       [80.  , 53.  , 29.95]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2D[1:4,:]  # this would be the second observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[79.  , 52.  , 29.94],\n",
       "       [80.  , 53.  , 29.95],\n",
       "       [78.  , 67.  , 29.96]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2D[2:5,:]  # this would be the third observation, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, this would be better to put into a function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length):\n",
    "    obs = []\n",
    "    print(obs)    \n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        obs.append(data[i:(i+seq_length)+1])\n",
    "    return np.array(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[77.  , 50.  , 29.92],\n",
       "        [78.  , 51.  , 29.93],\n",
       "        [79.  , 52.  , 29.94],\n",
       "        [80.  , 53.  , 29.95]],\n",
       "\n",
       "       [[78.  , 51.  , 29.93],\n",
       "        [79.  , 52.  , 29.94],\n",
       "        [80.  , 53.  , 29.95],\n",
       "        [78.  , 67.  , 29.96]],\n",
       "\n",
       "       [[79.  , 52.  , 29.94],\n",
       "        [80.  , 53.  , 29.95],\n",
       "        [78.  , 67.  , 29.96],\n",
       "        [82.  , 59.  , 29.97]],\n",
       "\n",
       "       [[80.  , 53.  , 29.95],\n",
       "        [78.  , 67.  , 29.96],\n",
       "        [82.  , 59.  , 29.97],\n",
       "        [76.  , 58.  , 29.98]],\n",
       "\n",
       "       [[78.  , 67.  , 29.96],\n",
       "        [82.  , 59.  , 29.97],\n",
       "        [76.  , 58.  , 29.98],\n",
       "        [76.  , 56.  , 29.99]],\n",
       "\n",
       "       [[82.  , 59.  , 29.97],\n",
       "        [76.  , 58.  , 29.98],\n",
       "        [76.  , 56.  , 29.99],\n",
       "        [85.  , 62.  , 30.  ]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_input = create_sequences(arr2D, 3)\n",
    "RNN_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the data we have created above.  We have 6 'observations', each with 3 time steps and 3 features (Temp, Humidity and Pressure).  The last row of each observation is the target value we want to predict. We only need the temp value from the last row of each observation (the other values are not needed - because if you're trying to predict tomorrow's weather, you don't have any measures from tomorrow, because it's the future :) )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now extract our target variable. In this case, we want to predict the next day's temperature, so we will extract the last temperature value from each sequence (observation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([80., 78., 82., 76., 76., 85.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = RNN_input[:,-1,0] # the 3 is the index of the column, and the 0 is the index of the row\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[77.  , 50.  , 29.92],\n",
       "        [78.  , 51.  , 29.93],\n",
       "        [79.  , 52.  , 29.94]],\n",
       "\n",
       "       [[78.  , 51.  , 29.93],\n",
       "        [79.  , 52.  , 29.94],\n",
       "        [80.  , 53.  , 29.95]],\n",
       "\n",
       "       [[79.  , 52.  , 29.94],\n",
       "        [80.  , 53.  , 29.95],\n",
       "        [78.  , 67.  , 29.96]],\n",
       "\n",
       "       [[80.  , 53.  , 29.95],\n",
       "        [78.  , 67.  , 29.96],\n",
       "        [82.  , 59.  , 29.97]],\n",
       "\n",
       "       [[78.  , 67.  , 29.96],\n",
       "        [82.  , 59.  , 29.97],\n",
       "        [76.  , 58.  , 29.98]],\n",
       "\n",
       "       [[82.  , 59.  , 29.97],\n",
       "        [76.  , 58.  , 29.98],\n",
       "        [76.  , 56.  , 29.99]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = RNN_input[:,0:3,0:3] # the 3 is the index of the column, and the 0 is the index of the row\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the data to a Recurrent neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[85.],\n",
       "       [82.],\n",
       "       [76.],\n",
       "       [76.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.reshape(-1,1)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[80.],\n",
       "       [78.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = y_test.reshape(-1,1)\n",
    "y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3, 3)\n",
      "(2, 3, 3)\n",
      "(4, 1)\n",
      "(2, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to split out data into train and test and normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[77.  , 50.  , 29.92, 78.  , 51.  , 29.93, 79.  , 52.  , 29.94],\n",
       "       [78.  , 51.  , 29.93, 79.  , 52.  , 29.94, 80.  , 53.  , 29.95]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.reshape(-1, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[82.  , 59.  , 29.97],\n",
       "        [76.  , 58.  , 29.98],\n",
       "        [76.  , 56.  , 29.99]],\n",
       "\n",
       "       [[79.  , 52.  , 29.94],\n",
       "        [80.  , 53.  , 29.95],\n",
       "        [78.  , 67.  , 29.96]],\n",
       "\n",
       "       [[78.  , 67.  , 29.96],\n",
       "        [82.  , 59.  , 29.97],\n",
       "        [76.  , 58.  , 29.98]],\n",
       "\n",
       "       [[80.  , 53.  , 29.95],\n",
       "        [78.  , 67.  , 29.96],\n",
       "        [82.  , 59.  , 29.97]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[82.  , 59.  , 29.97],\n",
       "       [76.  , 58.  , 29.98],\n",
       "       [76.  , 56.  , 29.99],\n",
       "       [79.  , 52.  , 29.94],\n",
       "       [80.  , 53.  , 29.95],\n",
       "       [78.  , 67.  , 29.96],\n",
       "       [78.  , 67.  , 29.96],\n",
       "       [82.  , 59.  , 29.97],\n",
       "       [76.  , 58.  , 29.98],\n",
       "       [80.  , 53.  , 29.95],\n",
       "       [78.  , 67.  , 29.96],\n",
       "       [82.  , 59.  , 29.97]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[82.  , 59.  , 29.97],\n",
       "        [76.  , 58.  , 29.98],\n",
       "        [76.  , 56.  , 29.99]],\n",
       "\n",
       "       [[79.  , 52.  , 29.94],\n",
       "        [80.  , 53.  , 29.95],\n",
       "        [78.  , 67.  , 29.96]],\n",
       "\n",
       "       [[78.  , 67.  , 29.96],\n",
       "        [82.  , 59.  , 29.97],\n",
       "        [76.  , 58.  , 29.98]],\n",
       "\n",
       "       [[80.  , 53.  , 29.95],\n",
       "        [78.  , 67.  , 29.96],\n",
       "        [82.  , 59.  , 29.97]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.reshape(-1, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27556\\3341996249.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_scaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX_train_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_scaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mX_test_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_scaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train_scaled = X_scaler.fit_transform(X_train.reshape(-1, 3))\n",
    "X_test_scaled = X_scaler.transform(X_train.reshape(-1, 3))\n",
    "\n",
    "\n",
    "y_scaler = MinMaxScaler(feature_range=(0, 1)) # I don't necessarily need to rescale the y values, but I may test doing this in the future\n",
    "y_scaler.fit(y_train.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.46666667, 0.6       ],\n",
       "       [0.        , 0.4       , 0.8       ],\n",
       "       [0.        , 0.26666667, 1.        ],\n",
       "       [0.5       , 0.        , 0.        ],\n",
       "       [0.66666667, 0.06666667, 0.2       ],\n",
       "       [0.33333333, 1.        , 0.4       ],\n",
       "       [0.33333333, 1.        , 0.4       ],\n",
       "       [1.        , 0.46666667, 0.6       ],\n",
       "       [0.        , 0.4       , 0.8       ],\n",
       "       [0.66666667, 0.06666667, 0.2       ],\n",
       "       [0.33333333, 1.        , 0.4       ],\n",
       "       [1.        , 0.46666667, 0.6       ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.        , 0.46666667, 0.6       ],\n",
       "        [0.        , 0.4       , 0.8       ],\n",
       "        [0.        , 0.26666667, 1.        ]],\n",
       "\n",
       "       [[0.5       , 0.        , 0.        ],\n",
       "        [0.66666667, 0.06666667, 0.2       ],\n",
       "        [0.33333333, 1.        , 0.4       ]],\n",
       "\n",
       "       [[0.33333333, 1.        , 0.4       ],\n",
       "        [1.        , 0.46666667, 0.6       ],\n",
       "        [0.        , 0.4       , 0.8       ]],\n",
       "\n",
       "       [[0.66666667, 0.06666667, 0.2       ],\n",
       "        [0.33333333, 1.        , 0.4       ],\n",
       "        [1.        , 0.46666667, 0.6       ]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.reshape(-1, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.46666667, 0.6       ],\n",
       "       [0.        , 0.4       , 0.8       ],\n",
       "       [0.        , 0.26666667, 1.        ],\n",
       "       [0.5       , 0.        , 0.        ],\n",
       "       [0.66666667, 0.06666667, 0.2       ],\n",
       "       [0.33333333, 1.        , 0.4       ],\n",
       "       [0.33333333, 1.        , 0.4       ],\n",
       "       [1.        , 0.46666667, 0.6       ],\n",
       "       [0.        , 0.4       , 0.8       ],\n",
       "       [0.66666667, 0.06666667, 0.2       ],\n",
       "       [0.33333333, 1.        , 0.4       ],\n",
       "       [1.        , 0.46666667, 0.6       ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to fit the data to a recurrent neural network.  We will use a simple RNN with 20 neurons in the hidden layer.  We will use the mean squared error loss function and the adam optimizer. Our input consists of 6 observations, each with 3 time steps and 3 features.  Our target is the temperature value for the last time step of each observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import SimpleRNN, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(20, input_shape=(3,3)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 20)                480       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 501\n",
      "Trainable params: 501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-28 15:34:48.152217: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 6276.8306\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 6263.4746\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 6250.1514\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 6236.8901\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 6223.5698\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 6210.4600\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 6197.4043\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 954us/step - loss: 6183.9009\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 938us/step - loss: 6170.7949\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 888us/step - loss: 6156.7144\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 927us/step - loss: 6140.5825\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 937us/step - loss: 6118.5698\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 928us/step - loss: 6090.5039\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 832us/step - loss: 6053.8970\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 952us/step - loss: 6016.1660\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 976us/step - loss: 5984.9014\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 886us/step - loss: 5965.0845\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 878us/step - loss: 5943.2095\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 940us/step - loss: 5924.3691\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 904us/step - loss: 5910.9087\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 939us/step - loss: 5896.6768\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 847us/step - loss: 5881.5000\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 812us/step - loss: 5869.1055\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 778us/step - loss: 5856.2036\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 728us/step - loss: 5843.8813\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 809us/step - loss: 5830.2886\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 814us/step - loss: 5814.8379\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 728us/step - loss: 5790.1880\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s 763us/step - loss: 5754.9858\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s 795us/step - loss: 5729.7974\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s 781us/step - loss: 5716.6963\n",
      "Epoch 32/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 5701.0845\n",
      "Epoch 33/500\n",
      "4/4 [==============================] - 0s 769us/step - loss: 5669.1245\n",
      "Epoch 34/500\n",
      "4/4 [==============================] - 0s 765us/step - loss: 5628.0469\n",
      "Epoch 35/500\n",
      "4/4 [==============================] - 0s 793us/step - loss: 5612.5923\n",
      "Epoch 36/500\n",
      "4/4 [==============================] - 0s 804us/step - loss: 5600.7524\n",
      "Epoch 37/500\n",
      "4/4 [==============================] - 0s 764us/step - loss: 5588.6367\n",
      "Epoch 38/500\n",
      "4/4 [==============================] - 0s 756us/step - loss: 5576.3408\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 5564.0005\n",
      "Epoch 40/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 5551.3491\n",
      "Epoch 41/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 5530.9395\n",
      "Epoch 42/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 5509.4502\n",
      "Epoch 43/500\n",
      "4/4 [==============================] - 0s 910us/step - loss: 5490.0381\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 5478.4570\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - 0s 989us/step - loss: 5466.4883\n",
      "Epoch 46/500\n",
      "4/4 [==============================] - 0s 840us/step - loss: 5454.4805\n",
      "Epoch 47/500\n",
      "4/4 [==============================] - 0s 838us/step - loss: 5442.6162\n",
      "Epoch 48/500\n",
      "4/4 [==============================] - 0s 759us/step - loss: 5430.7183\n",
      "Epoch 49/500\n",
      "4/4 [==============================] - 0s 754us/step - loss: 5418.8174\n",
      "Epoch 50/500\n",
      "4/4 [==============================] - 0s 951us/step - loss: 5406.7334\n",
      "Epoch 51/500\n",
      "4/4 [==============================] - 0s 812us/step - loss: 5394.7100\n",
      "Epoch 52/500\n",
      "4/4 [==============================] - 0s 766us/step - loss: 5382.8228\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - 0s 832us/step - loss: 5370.8589\n",
      "Epoch 54/500\n",
      "4/4 [==============================] - 0s 739us/step - loss: 5359.1050\n",
      "Epoch 55/500\n",
      "4/4 [==============================] - 0s 731us/step - loss: 5347.1304\n",
      "Epoch 56/500\n",
      "4/4 [==============================] - 0s 814us/step - loss: 5335.1582\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - 0s 790us/step - loss: 5323.3218\n",
      "Epoch 58/500\n",
      "4/4 [==============================] - 0s 795us/step - loss: 5311.3418\n",
      "Epoch 59/500\n",
      "4/4 [==============================] - 0s 755us/step - loss: 5299.6792\n",
      "Epoch 60/500\n",
      "4/4 [==============================] - 0s 746us/step - loss: 5287.7002\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - 0s 816us/step - loss: 5275.9434\n",
      "Epoch 62/500\n",
      "4/4 [==============================] - 0s 831us/step - loss: 5264.3350\n",
      "Epoch 63/500\n",
      "4/4 [==============================] - 0s 760us/step - loss: 5252.5566\n",
      "Epoch 64/500\n",
      "4/4 [==============================] - 0s 718us/step - loss: 5240.7192\n",
      "Epoch 65/500\n",
      "4/4 [==============================] - 0s 807us/step - loss: 5228.9092\n",
      "Epoch 66/500\n",
      "4/4 [==============================] - 0s 704us/step - loss: 5217.3438\n",
      "Epoch 67/500\n",
      "4/4 [==============================] - 0s 765us/step - loss: 5205.6621\n",
      "Epoch 68/500\n",
      "4/4 [==============================] - 0s 802us/step - loss: 5193.9883\n",
      "Epoch 69/500\n",
      "4/4 [==============================] - 0s 715us/step - loss: 5182.3423\n",
      "Epoch 70/500\n",
      "4/4 [==============================] - 0s 783us/step - loss: 5170.6484\n",
      "Epoch 71/500\n",
      "4/4 [==============================] - 0s 779us/step - loss: 5159.1689\n",
      "Epoch 72/500\n",
      "4/4 [==============================] - 0s 747us/step - loss: 5147.5249\n",
      "Epoch 73/500\n",
      "4/4 [==============================] - 0s 755us/step - loss: 5136.0293\n",
      "Epoch 74/500\n",
      "4/4 [==============================] - 0s 737us/step - loss: 5124.4189\n",
      "Epoch 75/500\n",
      "4/4 [==============================] - 0s 774us/step - loss: 5113.0044\n",
      "Epoch 76/500\n",
      "4/4 [==============================] - 0s 801us/step - loss: 5101.4746\n",
      "Epoch 77/500\n",
      "4/4 [==============================] - 0s 794us/step - loss: 5089.6772\n",
      "Epoch 78/500\n",
      "4/4 [==============================] - 0s 833us/step - loss: 5078.5215\n",
      "Epoch 79/500\n",
      "4/4 [==============================] - 0s 798us/step - loss: 5066.9551\n",
      "Epoch 80/500\n",
      "4/4 [==============================] - 0s 772us/step - loss: 5055.3442\n",
      "Epoch 81/500\n",
      "4/4 [==============================] - 0s 769us/step - loss: 5044.1147\n",
      "Epoch 82/500\n",
      "4/4 [==============================] - 0s 754us/step - loss: 5032.5811\n",
      "Epoch 83/500\n",
      "4/4 [==============================] - 0s 818us/step - loss: 5021.4165\n",
      "Epoch 84/500\n",
      "4/4 [==============================] - 0s 821us/step - loss: 5010.0234\n",
      "Epoch 85/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 4998.7578\n",
      "Epoch 86/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 4987.3403\n",
      "Epoch 87/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 4975.9570\n",
      "Epoch 88/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 4964.7061\n",
      "Epoch 89/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 4953.5381\n",
      "Epoch 90/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 4942.0840\n",
      "Epoch 91/500\n",
      "4/4 [==============================] - 0s 967us/step - loss: 4931.0215\n",
      "Epoch 92/500\n",
      "4/4 [==============================] - 0s 820us/step - loss: 4919.5752\n",
      "Epoch 93/500\n",
      "4/4 [==============================] - 0s 784us/step - loss: 4908.4707\n",
      "Epoch 94/500\n",
      "4/4 [==============================] - 0s 743us/step - loss: 4897.4004\n",
      "Epoch 95/500\n",
      "4/4 [==============================] - 0s 764us/step - loss: 4886.2417\n",
      "Epoch 96/500\n",
      "4/4 [==============================] - 0s 774us/step - loss: 4875.0957\n",
      "Epoch 97/500\n",
      "4/4 [==============================] - 0s 817us/step - loss: 4864.0391\n",
      "Epoch 98/500\n",
      "4/4 [==============================] - 0s 719us/step - loss: 4852.8945\n",
      "Epoch 99/500\n",
      "4/4 [==============================] - 0s 812us/step - loss: 4841.8447\n",
      "Epoch 100/500\n",
      "4/4 [==============================] - 0s 748us/step - loss: 4830.6499\n",
      "Epoch 101/500\n",
      "4/4 [==============================] - 0s 790us/step - loss: 4819.6846\n",
      "Epoch 102/500\n",
      "4/4 [==============================] - 0s 877us/step - loss: 4808.6909\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - 0s 767us/step - loss: 4797.6738\n",
      "Epoch 104/500\n",
      "4/4 [==============================] - 0s 812us/step - loss: 4786.7021\n",
      "Epoch 105/500\n",
      "4/4 [==============================] - 0s 853us/step - loss: 4775.8135\n",
      "Epoch 106/500\n",
      "4/4 [==============================] - 0s 878us/step - loss: 4764.7949\n",
      "Epoch 107/500\n",
      "4/4 [==============================] - 0s 767us/step - loss: 4753.8945\n",
      "Epoch 108/500\n",
      "4/4 [==============================] - 0s 779us/step - loss: 4742.6860\n",
      "Epoch 109/500\n",
      "4/4 [==============================] - 0s 755us/step - loss: 4732.0771\n",
      "Epoch 110/500\n",
      "4/4 [==============================] - 0s 891us/step - loss: 4721.0820\n",
      "Epoch 111/500\n",
      "4/4 [==============================] - 0s 761us/step - loss: 4710.2046\n",
      "Epoch 112/500\n",
      "4/4 [==============================] - 0s 760us/step - loss: 4699.3799\n",
      "Epoch 113/500\n",
      "4/4 [==============================] - 0s 752us/step - loss: 4688.5156\n",
      "Epoch 114/500\n",
      "4/4 [==============================] - 0s 821us/step - loss: 4677.9307\n",
      "Epoch 115/500\n",
      "4/4 [==============================] - 0s 726us/step - loss: 4667.1143\n",
      "Epoch 116/500\n",
      "4/4 [==============================] - 0s 751us/step - loss: 4656.1299\n",
      "Epoch 117/500\n",
      "4/4 [==============================] - 0s 726us/step - loss: 4645.5361\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - 0s 763us/step - loss: 4634.5645\n",
      "Epoch 119/500\n",
      "4/4 [==============================] - 0s 782us/step - loss: 4624.1240\n",
      "Epoch 120/500\n",
      "4/4 [==============================] - 0s 750us/step - loss: 4613.4404\n",
      "Epoch 121/500\n",
      "4/4 [==============================] - 0s 803us/step - loss: 4602.6196\n",
      "Epoch 122/500\n",
      "4/4 [==============================] - 0s 775us/step - loss: 4591.9312\n",
      "Epoch 123/500\n",
      "4/4 [==============================] - 0s 739us/step - loss: 4581.4204\n",
      "Epoch 124/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 4570.5718\n",
      "Epoch 125/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 4560.1143\n",
      "Epoch 126/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 4549.3955\n",
      "Epoch 127/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 4539.0786\n",
      "Epoch 128/500\n",
      "4/4 [==============================] - 0s 787us/step - loss: 4528.3252\n",
      "Epoch 129/500\n",
      "4/4 [==============================] - 0s 876us/step - loss: 4517.9600\n",
      "Epoch 130/500\n",
      "4/4 [==============================] - 0s 993us/step - loss: 4507.4038\n",
      "Epoch 131/500\n",
      "4/4 [==============================] - 0s 881us/step - loss: 4496.8057\n",
      "Epoch 132/500\n",
      "4/4 [==============================] - 0s 885us/step - loss: 4486.3228\n",
      "Epoch 133/500\n",
      "4/4 [==============================] - 0s 784us/step - loss: 4475.9668\n",
      "Epoch 134/500\n",
      "4/4 [==============================] - 0s 691us/step - loss: 4465.3960\n",
      "Epoch 135/500\n",
      "4/4 [==============================] - 0s 766us/step - loss: 4454.9360\n",
      "Epoch 136/500\n",
      "4/4 [==============================] - 0s 719us/step - loss: 4444.5698\n",
      "Epoch 137/500\n",
      "4/4 [==============================] - 0s 833us/step - loss: 4434.2461\n",
      "Epoch 138/500\n",
      "4/4 [==============================] - 0s 748us/step - loss: 4423.7632\n",
      "Epoch 139/500\n",
      "4/4 [==============================] - 0s 711us/step - loss: 4413.2959\n",
      "Epoch 140/500\n",
      "4/4 [==============================] - 0s 838us/step - loss: 4403.1040\n",
      "Epoch 141/500\n",
      "4/4 [==============================] - 0s 750us/step - loss: 4392.6846\n",
      "Epoch 142/500\n",
      "4/4 [==============================] - 0s 755us/step - loss: 4382.5811\n",
      "Epoch 143/500\n",
      "4/4 [==============================] - 0s 731us/step - loss: 4372.2490\n",
      "Epoch 144/500\n",
      "4/4 [==============================] - 0s 694us/step - loss: 4361.9214\n",
      "Epoch 145/500\n",
      "4/4 [==============================] - 0s 775us/step - loss: 4351.8018\n",
      "Epoch 146/500\n",
      "4/4 [==============================] - 0s 719us/step - loss: 4341.4697\n",
      "Epoch 147/500\n",
      "4/4 [==============================] - 0s 739us/step - loss: 4331.1836\n",
      "Epoch 148/500\n",
      "4/4 [==============================] - 0s 757us/step - loss: 4320.8750\n",
      "Epoch 149/500\n",
      "4/4 [==============================] - 0s 773us/step - loss: 4310.7339\n",
      "Epoch 150/500\n",
      "4/4 [==============================] - 0s 839us/step - loss: 4300.5942\n",
      "Epoch 151/500\n",
      "4/4 [==============================] - 0s 727us/step - loss: 4290.5645\n",
      "Epoch 152/500\n",
      "4/4 [==============================] - 0s 826us/step - loss: 4280.2603\n",
      "Epoch 153/500\n",
      "4/4 [==============================] - 0s 720us/step - loss: 4270.3042\n",
      "Epoch 154/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 4260.2744\n",
      "Epoch 155/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 4249.9854\n",
      "Epoch 156/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 4240.0703\n",
      "Epoch 157/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 4230.0732\n",
      "Epoch 158/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 4219.9795\n",
      "Epoch 159/500\n",
      "4/4 [==============================] - 0s 879us/step - loss: 4209.9985\n",
      "Epoch 160/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 4199.8145\n",
      "Epoch 161/500\n",
      "4/4 [==============================] - 0s 961us/step - loss: 4189.7783\n",
      "Epoch 162/500\n",
      "4/4 [==============================] - 0s 762us/step - loss: 4179.8740\n",
      "Epoch 163/500\n",
      "4/4 [==============================] - 0s 736us/step - loss: 4170.0913\n",
      "Epoch 164/500\n",
      "4/4 [==============================] - 0s 847us/step - loss: 4160.2339\n",
      "Epoch 165/500\n",
      "4/4 [==============================] - 0s 803us/step - loss: 4150.1187\n",
      "Epoch 166/500\n",
      "4/4 [==============================] - 0s 729us/step - loss: 4140.3672\n",
      "Epoch 167/500\n",
      "4/4 [==============================] - 0s 794us/step - loss: 4130.3135\n",
      "Epoch 168/500\n",
      "4/4 [==============================] - 0s 811us/step - loss: 4120.5210\n",
      "Epoch 169/500\n",
      "4/4 [==============================] - 0s 771us/step - loss: 4110.9312\n",
      "Epoch 170/500\n",
      "4/4 [==============================] - 0s 705us/step - loss: 4100.9053\n",
      "Epoch 171/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 4091.1411\n",
      "Epoch 172/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 4081.4082\n",
      "Epoch 173/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 4071.4890\n",
      "Epoch 174/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 4061.7913\n",
      "Epoch 175/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 4052.0925\n",
      "Epoch 176/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 4042.4001\n",
      "Epoch 177/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 4032.6199\n",
      "Epoch 178/500\n",
      "4/4 [==============================] - 0s 872us/step - loss: 4022.8142\n",
      "Epoch 179/500\n",
      "4/4 [==============================] - 0s 895us/step - loss: 4013.1797\n",
      "Epoch 180/500\n",
      "4/4 [==============================] - 0s 746us/step - loss: 4003.5767\n",
      "Epoch 181/500\n",
      "4/4 [==============================] - 0s 733us/step - loss: 3993.8462\n",
      "Epoch 182/500\n",
      "4/4 [==============================] - 0s 849us/step - loss: 3984.4448\n",
      "Epoch 183/500\n",
      "4/4 [==============================] - 0s 763us/step - loss: 3974.8481\n",
      "Epoch 184/500\n",
      "4/4 [==============================] - 0s 801us/step - loss: 3965.1201\n",
      "Epoch 185/500\n",
      "4/4 [==============================] - 0s 823us/step - loss: 3955.5542\n",
      "Epoch 186/500\n",
      "4/4 [==============================] - 0s 772us/step - loss: 3945.8457\n",
      "Epoch 187/500\n",
      "4/4 [==============================] - 0s 727us/step - loss: 3936.5715\n",
      "Epoch 188/500\n",
      "4/4 [==============================] - 0s 712us/step - loss: 3926.8062\n",
      "Epoch 189/500\n",
      "4/4 [==============================] - 0s 957us/step - loss: 3917.3938\n",
      "Epoch 190/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3908.0833\n",
      "Epoch 191/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3898.5654\n",
      "Epoch 192/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3888.8716\n",
      "Epoch 193/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3879.6392\n",
      "Epoch 194/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3870.1963\n",
      "Epoch 195/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3860.7651\n",
      "Epoch 196/500\n",
      "4/4 [==============================] - 0s 943us/step - loss: 3851.2495\n",
      "Epoch 197/500\n",
      "4/4 [==============================] - 0s 820us/step - loss: 3841.8867\n",
      "Epoch 198/500\n",
      "4/4 [==============================] - 0s 810us/step - loss: 3832.7188\n",
      "Epoch 199/500\n",
      "4/4 [==============================] - 0s 813us/step - loss: 3823.2764\n",
      "Epoch 200/500\n",
      "4/4 [==============================] - 0s 728us/step - loss: 3814.1003\n",
      "Epoch 201/500\n",
      "4/4 [==============================] - 0s 759us/step - loss: 3804.5107\n",
      "Epoch 202/500\n",
      "4/4 [==============================] - 0s 720us/step - loss: 3795.3589\n",
      "Epoch 203/500\n",
      "4/4 [==============================] - 0s 809us/step - loss: 3786.2424\n",
      "Epoch 204/500\n",
      "4/4 [==============================] - 0s 738us/step - loss: 3776.7959\n",
      "Epoch 205/500\n",
      "4/4 [==============================] - 0s 759us/step - loss: 3767.5259\n",
      "Epoch 206/500\n",
      "4/4 [==============================] - 0s 783us/step - loss: 3758.3850\n",
      "Epoch 207/500\n",
      "4/4 [==============================] - 0s 755us/step - loss: 3749.1279\n",
      "Epoch 208/500\n",
      "4/4 [==============================] - 0s 820us/step - loss: 3739.9014\n",
      "Epoch 209/500\n",
      "4/4 [==============================] - 0s 751us/step - loss: 3730.6953\n",
      "Epoch 210/500\n",
      "4/4 [==============================] - 0s 726us/step - loss: 3721.7639\n",
      "Epoch 211/500\n",
      "4/4 [==============================] - 0s 731us/step - loss: 3712.5154\n",
      "Epoch 212/500\n",
      "4/4 [==============================] - 0s 915us/step - loss: 3703.2524\n",
      "Epoch 213/500\n",
      "4/4 [==============================] - 0s 789us/step - loss: 3694.1626\n",
      "Epoch 214/500\n",
      "4/4 [==============================] - 0s 773us/step - loss: 3685.1426\n",
      "Epoch 215/500\n",
      "4/4 [==============================] - 0s 796us/step - loss: 3675.8950\n",
      "Epoch 216/500\n",
      "4/4 [==============================] - 0s 777us/step - loss: 3667.0291\n",
      "Epoch 217/500\n",
      "4/4 [==============================] - 0s 754us/step - loss: 3657.8872\n",
      "Epoch 218/500\n",
      "4/4 [==============================] - 0s 754us/step - loss: 3648.8613\n",
      "Epoch 219/500\n",
      "4/4 [==============================] - 0s 724us/step - loss: 3639.9175\n",
      "Epoch 220/500\n",
      "4/4 [==============================] - 0s 731us/step - loss: 3630.9919\n",
      "Epoch 221/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3621.7952\n",
      "Epoch 222/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3612.9192\n",
      "Epoch 223/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3603.8962\n",
      "Epoch 224/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3595.0869\n",
      "Epoch 225/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3586.0186\n",
      "Epoch 226/500\n",
      "4/4 [==============================] - 0s 886us/step - loss: 3577.0483\n",
      "Epoch 227/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3568.3618\n",
      "Epoch 228/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3559.3848\n",
      "Epoch 229/500\n",
      "4/4 [==============================] - 0s 986us/step - loss: 3550.4922\n",
      "Epoch 230/500\n",
      "4/4 [==============================] - 0s 987us/step - loss: 3541.6670\n",
      "Epoch 231/500\n",
      "4/4 [==============================] - 0s 957us/step - loss: 3532.9609\n",
      "Epoch 232/500\n",
      "4/4 [==============================] - 0s 989us/step - loss: 3523.9905\n",
      "Epoch 233/500\n",
      "4/4 [==============================] - 0s 915us/step - loss: 3515.2788\n",
      "Epoch 234/500\n",
      "4/4 [==============================] - 0s 994us/step - loss: 3506.6582\n",
      "Epoch 235/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3497.8137\n",
      "Epoch 236/500\n",
      "4/4 [==============================] - 0s 926us/step - loss: 3488.9575\n",
      "Epoch 237/500\n",
      "4/4 [==============================] - 0s 823us/step - loss: 3480.1196\n",
      "Epoch 238/500\n",
      "4/4 [==============================] - 0s 909us/step - loss: 3471.4211\n",
      "Epoch 239/500\n",
      "4/4 [==============================] - 0s 968us/step - loss: 3462.8682\n",
      "Epoch 240/500\n",
      "4/4 [==============================] - 0s 881us/step - loss: 3454.1621\n",
      "Epoch 241/500\n",
      "4/4 [==============================] - 0s 775us/step - loss: 3445.5854\n",
      "Epoch 242/500\n",
      "4/4 [==============================] - 0s 724us/step - loss: 3436.7285\n",
      "Epoch 243/500\n",
      "4/4 [==============================] - 0s 791us/step - loss: 3428.1055\n",
      "Epoch 244/500\n",
      "4/4 [==============================] - 0s 762us/step - loss: 3419.4980\n",
      "Epoch 245/500\n",
      "4/4 [==============================] - 0s 746us/step - loss: 3410.8149\n",
      "Epoch 246/500\n",
      "4/4 [==============================] - 0s 725us/step - loss: 3402.3010\n",
      "Epoch 247/500\n",
      "4/4 [==============================] - 0s 740us/step - loss: 3393.8892\n",
      "Epoch 248/500\n",
      "4/4 [==============================] - 0s 775us/step - loss: 3385.1196\n",
      "Epoch 249/500\n",
      "4/4 [==============================] - 0s 776us/step - loss: 3376.5732\n",
      "Epoch 250/500\n",
      "4/4 [==============================] - 0s 740us/step - loss: 3368.0369\n",
      "Epoch 251/500\n",
      "4/4 [==============================] - 0s 858us/step - loss: 3359.7896\n",
      "Epoch 252/500\n",
      "4/4 [==============================] - 0s 763us/step - loss: 3351.0549\n",
      "Epoch 253/500\n",
      "4/4 [==============================] - 0s 783us/step - loss: 3342.6516\n",
      "Epoch 254/500\n",
      "4/4 [==============================] - 0s 724us/step - loss: 3334.0464\n",
      "Epoch 255/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3325.6162\n",
      "Epoch 256/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3317.2324\n",
      "Epoch 257/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3308.8047\n",
      "Epoch 258/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3300.4268\n",
      "Epoch 259/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3291.9841\n",
      "Epoch 260/500\n",
      "4/4 [==============================] - 0s 875us/step - loss: 3283.5669\n",
      "Epoch 261/500\n",
      "4/4 [==============================] - 0s 898us/step - loss: 3275.3999\n",
      "Epoch 262/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3266.7734\n",
      "Epoch 263/500\n",
      "4/4 [==============================] - 0s 792us/step - loss: 3258.5991\n",
      "Epoch 264/500\n",
      "4/4 [==============================] - 0s 729us/step - loss: 3250.1741\n",
      "Epoch 265/500\n",
      "4/4 [==============================] - 0s 762us/step - loss: 3241.9526\n",
      "Epoch 266/500\n",
      "4/4 [==============================] - 0s 835us/step - loss: 3233.6587\n",
      "Epoch 267/500\n",
      "4/4 [==============================] - 0s 814us/step - loss: 3225.4551\n",
      "Epoch 268/500\n",
      "4/4 [==============================] - 0s 711us/step - loss: 3217.0942\n",
      "Epoch 269/500\n",
      "4/4 [==============================] - 0s 683us/step - loss: 3208.9739\n",
      "Epoch 270/500\n",
      "4/4 [==============================] - 0s 764us/step - loss: 3200.5344\n",
      "Epoch 271/500\n",
      "4/4 [==============================] - 0s 791us/step - loss: 3192.4829\n",
      "Epoch 272/500\n",
      "4/4 [==============================] - 0s 731us/step - loss: 3184.2654\n",
      "Epoch 273/500\n",
      "4/4 [==============================] - 0s 829us/step - loss: 3175.9622\n",
      "Epoch 274/500\n",
      "4/4 [==============================] - 0s 746us/step - loss: 3167.9277\n",
      "Epoch 275/500\n",
      "4/4 [==============================] - 0s 801us/step - loss: 3159.6958\n",
      "Epoch 276/500\n",
      "4/4 [==============================] - 0s 792us/step - loss: 3151.5645\n",
      "Epoch 277/500\n",
      "4/4 [==============================] - 0s 872us/step - loss: 3143.4453\n",
      "Epoch 278/500\n",
      "4/4 [==============================] - 0s 767us/step - loss: 3135.3994\n",
      "Epoch 279/500\n",
      "4/4 [==============================] - 0s 909us/step - loss: 3127.1367\n",
      "Epoch 280/500\n",
      "4/4 [==============================] - 0s 810us/step - loss: 3119.2349\n",
      "Epoch 281/500\n",
      "4/4 [==============================] - 0s 719us/step - loss: 3111.1255\n",
      "Epoch 282/500\n",
      "4/4 [==============================] - 0s 773us/step - loss: 3103.1077\n",
      "Epoch 283/500\n",
      "4/4 [==============================] - 0s 759us/step - loss: 3095.1213\n",
      "Epoch 284/500\n",
      "4/4 [==============================] - 0s 767us/step - loss: 3086.9927\n",
      "Epoch 285/500\n",
      "4/4 [==============================] - 0s 720us/step - loss: 3078.9956\n",
      "Epoch 286/500\n",
      "4/4 [==============================] - 0s 942us/step - loss: 3071.0457\n",
      "Epoch 287/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3063.0127\n",
      "Epoch 288/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3055.0557\n",
      "Epoch 289/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3047.1531\n",
      "Epoch 290/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3039.0117\n",
      "Epoch 291/500\n",
      "4/4 [==============================] - 0s 890us/step - loss: 3031.1951\n",
      "Epoch 292/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3023.4700\n",
      "Epoch 293/500\n",
      "4/4 [==============================] - 0s 791us/step - loss: 3015.3467\n",
      "Epoch 294/500\n",
      "4/4 [==============================] - 0s 824us/step - loss: 3007.7126\n",
      "Epoch 295/500\n",
      "4/4 [==============================] - 0s 718us/step - loss: 2999.8386\n",
      "Epoch 296/500\n",
      "4/4 [==============================] - 0s 747us/step - loss: 2991.8757\n",
      "Epoch 297/500\n",
      "4/4 [==============================] - 0s 805us/step - loss: 2984.1350\n",
      "Epoch 298/500\n",
      "4/4 [==============================] - 0s 802us/step - loss: 2976.2217\n",
      "Epoch 299/500\n",
      "4/4 [==============================] - 0s 825us/step - loss: 2968.5022\n",
      "Epoch 300/500\n",
      "4/4 [==============================] - 0s 843us/step - loss: 2960.5581\n",
      "Epoch 301/500\n",
      "4/4 [==============================] - 0s 890us/step - loss: 2952.8528\n",
      "Epoch 302/500\n",
      "4/4 [==============================] - 0s 716us/step - loss: 2945.0337\n",
      "Epoch 303/500\n",
      "4/4 [==============================] - 0s 737us/step - loss: 2937.3022\n",
      "Epoch 304/500\n",
      "4/4 [==============================] - 0s 712us/step - loss: 2929.7305\n",
      "Epoch 305/500\n",
      "4/4 [==============================] - 0s 854us/step - loss: 2921.8584\n",
      "Epoch 306/500\n",
      "4/4 [==============================] - 0s 741us/step - loss: 2914.2427\n",
      "Epoch 307/500\n",
      "4/4 [==============================] - 0s 754us/step - loss: 2906.6924\n",
      "Epoch 308/500\n",
      "4/4 [==============================] - 0s 717us/step - loss: 2898.8989\n",
      "Epoch 309/500\n",
      "4/4 [==============================] - 0s 808us/step - loss: 2891.1753\n",
      "Epoch 310/500\n",
      "4/4 [==============================] - 0s 773us/step - loss: 2883.5469\n",
      "Epoch 311/500\n",
      "4/4 [==============================] - 0s 739us/step - loss: 2876.0347\n",
      "Epoch 312/500\n",
      "4/4 [==============================] - 0s 741us/step - loss: 2868.3481\n",
      "Epoch 313/500\n",
      "4/4 [==============================] - 0s 686us/step - loss: 2860.5889\n",
      "Epoch 314/500\n",
      "4/4 [==============================] - 0s 737us/step - loss: 2853.2900\n",
      "Epoch 315/500\n",
      "4/4 [==============================] - 0s 771us/step - loss: 2845.6245\n",
      "Epoch 316/500\n",
      "4/4 [==============================] - 0s 821us/step - loss: 2837.9905\n",
      "Epoch 317/500\n",
      "4/4 [==============================] - 0s 793us/step - loss: 2830.5574\n",
      "Epoch 318/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2822.9551\n",
      "Epoch 319/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2815.4795\n",
      "Epoch 320/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2807.7236\n",
      "Epoch 321/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2800.4404\n",
      "Epoch 322/500\n",
      "4/4 [==============================] - 0s 992us/step - loss: 2792.9839\n",
      "Epoch 323/500\n",
      "4/4 [==============================] - 0s 991us/step - loss: 2785.3657\n",
      "Epoch 324/500\n",
      "4/4 [==============================] - 0s 855us/step - loss: 2778.1140\n",
      "Epoch 325/500\n",
      "4/4 [==============================] - 0s 815us/step - loss: 2770.5420\n",
      "Epoch 326/500\n",
      "4/4 [==============================] - 0s 755us/step - loss: 2763.2446\n",
      "Epoch 327/500\n",
      "4/4 [==============================] - 0s 823us/step - loss: 2755.9099\n",
      "Epoch 328/500\n",
      "4/4 [==============================] - 0s 825us/step - loss: 2748.4380\n",
      "Epoch 329/500\n",
      "4/4 [==============================] - 0s 843us/step - loss: 2741.0559\n",
      "Epoch 330/500\n",
      "4/4 [==============================] - 0s 760us/step - loss: 2733.7388\n",
      "Epoch 331/500\n",
      "4/4 [==============================] - 0s 804us/step - loss: 2726.2605\n",
      "Epoch 332/500\n",
      "4/4 [==============================] - 0s 686us/step - loss: 2718.9592\n",
      "Epoch 333/500\n",
      "4/4 [==============================] - 0s 834us/step - loss: 2711.7598\n",
      "Epoch 334/500\n",
      "4/4 [==============================] - 0s 806us/step - loss: 2704.3704\n",
      "Epoch 335/500\n",
      "4/4 [==============================] - 0s 732us/step - loss: 2697.1626\n",
      "Epoch 336/500\n",
      "4/4 [==============================] - 0s 846us/step - loss: 2689.6431\n",
      "Epoch 337/500\n",
      "4/4 [==============================] - 0s 760us/step - loss: 2682.5864\n",
      "Epoch 338/500\n",
      "4/4 [==============================] - 0s 750us/step - loss: 2675.1934\n",
      "Epoch 339/500\n",
      "4/4 [==============================] - 0s 713us/step - loss: 2668.0479\n",
      "Epoch 340/500\n",
      "4/4 [==============================] - 0s 793us/step - loss: 2660.8992\n",
      "Epoch 341/500\n",
      "4/4 [==============================] - 0s 758us/step - loss: 2653.7322\n",
      "Epoch 342/500\n",
      "4/4 [==============================] - 0s 796us/step - loss: 2646.4189\n",
      "Epoch 343/500\n",
      "4/4 [==============================] - 0s 773us/step - loss: 2639.1936\n",
      "Epoch 344/500\n",
      "4/4 [==============================] - 0s 719us/step - loss: 2632.0002\n",
      "Epoch 345/500\n",
      "4/4 [==============================] - 0s 714us/step - loss: 2624.9443\n",
      "Epoch 346/500\n",
      "4/4 [==============================] - 0s 696us/step - loss: 2617.7971\n",
      "Epoch 347/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2610.5774\n",
      "Epoch 348/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2603.6191\n",
      "Epoch 349/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2596.5786\n",
      "Epoch 350/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2589.4287\n",
      "Epoch 351/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2582.3340\n",
      "Epoch 352/500\n",
      "4/4 [==============================] - 0s 880us/step - loss: 2575.0698\n",
      "Epoch 353/500\n",
      "4/4 [==============================] - 0s 952us/step - loss: 2568.1899\n",
      "Epoch 354/500\n",
      "4/4 [==============================] - 0s 941us/step - loss: 2561.2146\n",
      "Epoch 355/500\n",
      "4/4 [==============================] - 0s 768us/step - loss: 2554.0979\n",
      "Epoch 356/500\n",
      "4/4 [==============================] - 0s 705us/step - loss: 2547.2288\n",
      "Epoch 357/500\n",
      "4/4 [==============================] - 0s 837us/step - loss: 2539.9729\n",
      "Epoch 358/500\n",
      "4/4 [==============================] - 0s 836us/step - loss: 2533.2673\n",
      "Epoch 359/500\n",
      "4/4 [==============================] - 0s 806us/step - loss: 2526.2051\n",
      "Epoch 360/500\n",
      "4/4 [==============================] - 0s 771us/step - loss: 2519.3174\n",
      "Epoch 361/500\n",
      "4/4 [==============================] - 0s 715us/step - loss: 2512.2773\n",
      "Epoch 362/500\n",
      "4/4 [==============================] - 0s 675us/step - loss: 2505.3201\n",
      "Epoch 363/500\n",
      "4/4 [==============================] - 0s 713us/step - loss: 2498.3899\n",
      "Epoch 364/500\n",
      "4/4 [==============================] - 0s 961us/step - loss: 2491.7153\n",
      "Epoch 365/500\n",
      "4/4 [==============================] - 0s 869us/step - loss: 2484.6978\n",
      "Epoch 366/500\n",
      "4/4 [==============================] - 0s 957us/step - loss: 2477.9187\n",
      "Epoch 367/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2470.8867\n",
      "Epoch 368/500\n",
      "4/4 [==============================] - 0s 954us/step - loss: 2463.9883\n",
      "Epoch 369/500\n",
      "4/4 [==============================] - 0s 947us/step - loss: 2457.3179\n",
      "Epoch 370/500\n",
      "4/4 [==============================] - 0s 940us/step - loss: 2450.6162\n",
      "Epoch 371/500\n",
      "4/4 [==============================] - 0s 890us/step - loss: 2443.6787\n",
      "Epoch 372/500\n",
      "4/4 [==============================] - 0s 916us/step - loss: 2436.8267\n",
      "Epoch 373/500\n",
      "4/4 [==============================] - 0s 809us/step - loss: 2430.0342\n",
      "Epoch 374/500\n",
      "4/4 [==============================] - 0s 860us/step - loss: 2423.2561\n",
      "Epoch 375/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2416.5784\n",
      "Epoch 376/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2410.0388\n",
      "Epoch 377/500\n",
      "4/4 [==============================] - 0s 834us/step - loss: 2403.2542\n",
      "Epoch 378/500\n",
      "4/4 [==============================] - 0s 802us/step - loss: 2396.4614\n",
      "Epoch 379/500\n",
      "4/4 [==============================] - 0s 717us/step - loss: 2389.5879\n",
      "Epoch 380/500\n",
      "4/4 [==============================] - 0s 811us/step - loss: 2383.0598\n",
      "Epoch 381/500\n",
      "4/4 [==============================] - 0s 776us/step - loss: 2376.3997\n",
      "Epoch 382/500\n",
      "4/4 [==============================] - 0s 762us/step - loss: 2369.8152\n",
      "Epoch 383/500\n",
      "4/4 [==============================] - 0s 743us/step - loss: 2362.9846\n",
      "Epoch 384/500\n",
      "4/4 [==============================] - 0s 749us/step - loss: 2356.5337\n",
      "Epoch 385/500\n",
      "4/4 [==============================] - 0s 689us/step - loss: 2349.8635\n",
      "Epoch 386/500\n",
      "4/4 [==============================] - 0s 748us/step - loss: 2343.0737\n",
      "Epoch 387/500\n",
      "4/4 [==============================] - 0s 658us/step - loss: 2336.6348\n",
      "Epoch 388/500\n",
      "4/4 [==============================] - 0s 714us/step - loss: 2330.0896\n",
      "Epoch 389/500\n",
      "4/4 [==============================] - 0s 772us/step - loss: 2323.4663\n",
      "Epoch 390/500\n",
      "4/4 [==============================] - 0s 690us/step - loss: 2316.7905\n",
      "Epoch 391/500\n",
      "4/4 [==============================] - 0s 771us/step - loss: 2310.5000\n",
      "Epoch 392/500\n",
      "4/4 [==============================] - 0s 644us/step - loss: 2303.8320\n",
      "Epoch 393/500\n",
      "4/4 [==============================] - 0s 635us/step - loss: 2297.3794\n",
      "Epoch 394/500\n",
      "4/4 [==============================] - 0s 794us/step - loss: 2290.8059\n",
      "Epoch 395/500\n",
      "4/4 [==============================] - 0s 743us/step - loss: 2284.3423\n",
      "Epoch 396/500\n",
      "4/4 [==============================] - 0s 674us/step - loss: 2277.8662\n",
      "Epoch 397/500\n",
      "4/4 [==============================] - 0s 756us/step - loss: 2271.2793\n",
      "Epoch 398/500\n",
      "4/4 [==============================] - 0s 717us/step - loss: 2264.9778\n",
      "Epoch 399/500\n",
      "4/4 [==============================] - 0s 701us/step - loss: 2258.5310\n",
      "Epoch 400/500\n",
      "4/4 [==============================] - 0s 872us/step - loss: 2252.0479\n",
      "Epoch 401/500\n",
      "4/4 [==============================] - 0s 660us/step - loss: 2245.5942\n",
      "Epoch 402/500\n",
      "4/4 [==============================] - 0s 671us/step - loss: 2239.3857\n",
      "Epoch 403/500\n",
      "4/4 [==============================] - 0s 781us/step - loss: 2232.9846\n",
      "Epoch 404/500\n",
      "4/4 [==============================] - 0s 715us/step - loss: 2226.5972\n",
      "Epoch 405/500\n",
      "4/4 [==============================] - 0s 802us/step - loss: 2220.1665\n",
      "Epoch 406/500\n",
      "4/4 [==============================] - 0s 789us/step - loss: 2213.8560\n",
      "Epoch 407/500\n",
      "4/4 [==============================] - 0s 752us/step - loss: 2207.4167\n",
      "Epoch 408/500\n",
      "4/4 [==============================] - 0s 759us/step - loss: 2201.1021\n",
      "Epoch 409/500\n",
      "4/4 [==============================] - 0s 808us/step - loss: 2194.8633\n",
      "Epoch 410/500\n",
      "4/4 [==============================] - 0s 754us/step - loss: 2188.5117\n",
      "Epoch 411/500\n",
      "4/4 [==============================] - 0s 732us/step - loss: 2182.1812\n",
      "Epoch 412/500\n",
      "4/4 [==============================] - 0s 746us/step - loss: 2175.9897\n",
      "Epoch 413/500\n",
      "4/4 [==============================] - 0s 767us/step - loss: 2169.7729\n",
      "Epoch 414/500\n",
      "4/4 [==============================] - 0s 700us/step - loss: 2163.3474\n",
      "Epoch 415/500\n",
      "4/4 [==============================] - 0s 761us/step - loss: 2157.3413\n",
      "Epoch 416/500\n",
      "4/4 [==============================] - 0s 662us/step - loss: 2151.0229\n",
      "Epoch 417/500\n",
      "4/4 [==============================] - 0s 730us/step - loss: 2144.6902\n",
      "Epoch 418/500\n",
      "4/4 [==============================] - 0s 742us/step - loss: 2138.5112\n",
      "Epoch 419/500\n",
      "4/4 [==============================] - 0s 708us/step - loss: 2132.5454\n",
      "Epoch 420/500\n",
      "4/4 [==============================] - 0s 676us/step - loss: 2126.3330\n",
      "Epoch 421/500\n",
      "4/4 [==============================] - 0s 695us/step - loss: 2120.0464\n",
      "Epoch 422/500\n",
      "4/4 [==============================] - 0s 745us/step - loss: 2113.8335\n",
      "Epoch 423/500\n",
      "4/4 [==============================] - 0s 746us/step - loss: 2107.8828\n",
      "Epoch 424/500\n",
      "4/4 [==============================] - 0s 796us/step - loss: 2101.7002\n",
      "Epoch 425/500\n",
      "4/4 [==============================] - 0s 763us/step - loss: 2095.6636\n",
      "Epoch 426/500\n",
      "4/4 [==============================] - 0s 825us/step - loss: 2089.4995\n",
      "Epoch 427/500\n",
      "4/4 [==============================] - 0s 841us/step - loss: 2083.3484\n",
      "Epoch 428/500\n",
      "4/4 [==============================] - 0s 814us/step - loss: 2077.3550\n",
      "Epoch 429/500\n",
      "4/4 [==============================] - 0s 740us/step - loss: 2071.1423\n",
      "Epoch 430/500\n",
      "4/4 [==============================] - 0s 821us/step - loss: 2065.1592\n",
      "Epoch 431/500\n",
      "4/4 [==============================] - 0s 853us/step - loss: 2059.2661\n",
      "Epoch 432/500\n",
      "4/4 [==============================] - 0s 757us/step - loss: 2053.0930\n",
      "Epoch 433/500\n",
      "4/4 [==============================] - 0s 746us/step - loss: 2047.1653\n",
      "Epoch 434/500\n",
      "4/4 [==============================] - 0s 758us/step - loss: 2041.2225\n",
      "Epoch 435/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2035.0903\n",
      "Epoch 436/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2029.3022\n",
      "Epoch 437/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2023.2474\n",
      "Epoch 438/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2017.3469\n",
      "Epoch 439/500\n",
      "4/4 [==============================] - 0s 896us/step - loss: 2011.2451\n",
      "Epoch 440/500\n",
      "4/4 [==============================] - 0s 951us/step - loss: 2005.3137\n",
      "Epoch 441/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1999.5798\n",
      "Epoch 442/500\n",
      "4/4 [==============================] - 0s 923us/step - loss: 1993.6168\n",
      "Epoch 443/500\n",
      "4/4 [==============================] - 0s 746us/step - loss: 1987.7441\n",
      "Epoch 444/500\n",
      "4/4 [==============================] - 0s 766us/step - loss: 1981.7538\n",
      "Epoch 445/500\n",
      "4/4 [==============================] - 0s 815us/step - loss: 1975.9360\n",
      "Epoch 446/500\n",
      "4/4 [==============================] - 0s 770us/step - loss: 1970.2390\n",
      "Epoch 447/500\n",
      "4/4 [==============================] - 0s 731us/step - loss: 1964.2847\n",
      "Epoch 448/500\n",
      "4/4 [==============================] - 0s 817us/step - loss: 1958.4316\n",
      "Epoch 449/500\n",
      "4/4 [==============================] - 0s 814us/step - loss: 1952.7458\n",
      "Epoch 450/500\n",
      "4/4 [==============================] - 0s 670us/step - loss: 1946.8451\n",
      "Epoch 451/500\n",
      "4/4 [==============================] - 0s 844us/step - loss: 1941.0146\n",
      "Epoch 452/500\n",
      "4/4 [==============================] - 0s 709us/step - loss: 1935.2212\n",
      "Epoch 453/500\n",
      "4/4 [==============================] - 0s 782us/step - loss: 1929.5232\n",
      "Epoch 454/500\n",
      "4/4 [==============================] - 0s 765us/step - loss: 1923.7656\n",
      "Epoch 455/500\n",
      "4/4 [==============================] - 0s 726us/step - loss: 1918.0529\n",
      "Epoch 456/500\n",
      "4/4 [==============================] - 0s 673us/step - loss: 1912.1992\n",
      "Epoch 457/500\n",
      "4/4 [==============================] - 0s 831us/step - loss: 1906.5636\n",
      "Epoch 458/500\n",
      "4/4 [==============================] - 0s 693us/step - loss: 1900.7910\n",
      "Epoch 459/500\n",
      "4/4 [==============================] - 0s 644us/step - loss: 1895.0769\n",
      "Epoch 460/500\n",
      "4/4 [==============================] - 0s 751us/step - loss: 1889.5981\n",
      "Epoch 461/500\n",
      "4/4 [==============================] - 0s 729us/step - loss: 1883.7949\n",
      "Epoch 462/500\n",
      "4/4 [==============================] - 0s 825us/step - loss: 1877.9991\n",
      "Epoch 463/500\n",
      "4/4 [==============================] - 0s 770us/step - loss: 1872.5013\n",
      "Epoch 464/500\n",
      "4/4 [==============================] - 0s 716us/step - loss: 1866.9736\n",
      "Epoch 465/500\n",
      "4/4 [==============================] - 0s 646us/step - loss: 1861.2883\n",
      "Epoch 466/500\n",
      "4/4 [==============================] - 0s 869us/step - loss: 1855.4924\n",
      "Epoch 467/500\n",
      "4/4 [==============================] - 0s 776us/step - loss: 1850.0338\n",
      "Epoch 468/500\n",
      "4/4 [==============================] - 0s 647us/step - loss: 1844.3186\n",
      "Epoch 469/500\n",
      "4/4 [==============================] - 0s 761us/step - loss: 1838.9338\n",
      "Epoch 470/500\n",
      "4/4 [==============================] - 0s 748us/step - loss: 1833.2648\n",
      "Epoch 471/500\n",
      "4/4 [==============================] - 0s 721us/step - loss: 1827.6506\n",
      "Epoch 472/500\n",
      "4/4 [==============================] - 0s 723us/step - loss: 1822.3148\n",
      "Epoch 473/500\n",
      "4/4 [==============================] - 0s 776us/step - loss: 1816.6268\n",
      "Epoch 474/500\n",
      "4/4 [==============================] - 0s 782us/step - loss: 1811.2139\n",
      "Epoch 475/500\n",
      "4/4 [==============================] - 0s 743us/step - loss: 1805.6053\n",
      "Epoch 476/500\n",
      "4/4 [==============================] - 0s 713us/step - loss: 1800.1287\n",
      "Epoch 477/500\n",
      "4/4 [==============================] - 0s 754us/step - loss: 1794.5536\n",
      "Epoch 478/500\n",
      "4/4 [==============================] - 0s 816us/step - loss: 1789.1512\n",
      "Epoch 479/500\n",
      "4/4 [==============================] - 0s 767us/step - loss: 1783.7317\n",
      "Epoch 480/500\n",
      "4/4 [==============================] - 0s 800us/step - loss: 1778.2500\n",
      "Epoch 481/500\n",
      "4/4 [==============================] - 0s 768us/step - loss: 1772.7855\n",
      "Epoch 482/500\n",
      "4/4 [==============================] - 0s 763us/step - loss: 1767.4192\n",
      "Epoch 483/500\n",
      "4/4 [==============================] - 0s 697us/step - loss: 1762.1406\n",
      "Epoch 484/500\n",
      "4/4 [==============================] - 0s 763us/step - loss: 1756.6722\n",
      "Epoch 485/500\n",
      "4/4 [==============================] - 0s 733us/step - loss: 1751.0795\n",
      "Epoch 486/500\n",
      "4/4 [==============================] - 0s 644us/step - loss: 1745.8024\n",
      "Epoch 487/500\n",
      "4/4 [==============================] - 0s 838us/step - loss: 1740.4028\n",
      "Epoch 488/500\n",
      "4/4 [==============================] - 0s 684us/step - loss: 1735.1516\n",
      "Epoch 489/500\n",
      "4/4 [==============================] - 0s 746us/step - loss: 1729.7063\n",
      "Epoch 490/500\n",
      "4/4 [==============================] - 0s 843us/step - loss: 1724.4768\n",
      "Epoch 491/500\n",
      "4/4 [==============================] - 0s 713us/step - loss: 1719.0371\n",
      "Epoch 492/500\n",
      "4/4 [==============================] - 0s 663us/step - loss: 1713.9061\n",
      "Epoch 493/500\n",
      "4/4 [==============================] - 0s 755us/step - loss: 1708.3943\n",
      "Epoch 494/500\n",
      "4/4 [==============================] - 0s 822us/step - loss: 1703.1812\n",
      "Epoch 495/500\n",
      "4/4 [==============================] - 0s 634us/step - loss: 1698.0540\n",
      "Epoch 496/500\n",
      "4/4 [==============================] - 0s 871us/step - loss: 1692.5948\n",
      "Epoch 497/500\n",
      "4/4 [==============================] - 0s 752us/step - loss: 1687.5635\n",
      "Epoch 498/500\n",
      "4/4 [==============================] - 0s 737us/step - loss: 1682.2332\n",
      "Epoch 499/500\n",
      "4/4 [==============================] - 0s 717us/step - loss: 1676.9851\n",
      "Epoch 500/500\n",
      "4/4 [==============================] - 0s 648us/step - loss: 1671.7173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28a6e9c30>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=500, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now investigate the predictions of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[80.],\n",
       "       [78.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[39.089912],\n",
       "       [39.08992 ]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39.089912],\n",
       "       [39.08992 ]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.0</td>\n",
       "      <td>39.089912</td>\n",
       "      <td>40.910088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78.0</td>\n",
       "      <td>39.089920</td>\n",
       "      <td>38.910080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actual  predicted   residual\n",
       "0    80.0  39.089912  40.910088\n",
       "1    78.0  39.089920  38.910080"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "results['actual'] = y_test.flatten()\n",
    "results['predicted'] = y_pred.flatten()\n",
    "results['residual'] = results['actual'] - results['predicted']\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(results['actual'], label = 'actual')\n",
    "plt.plot(results['predicted'], label = 'predicted')\n",
    "plt.plot(results['residual'], label = 'residual')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the above graph isn't very interesting, as the dataset was very small (for illustration purposes). This smaller dataset makes it easier to see the structure of the data (since we can see every observation). For larger datasets, the approach is the same - only there will be more observations, possible different length timesteps, and different features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
