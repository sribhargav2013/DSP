{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1 - AIRBNB - CORE STEPS\n",
    "\n",
    "In this notebook we focus on the data loading, basic exploring, and prepatation.\n",
    "\n",
    "After reviewing and studying this material you should be able to:\n",
    "1. Import and install python libraries\n",
    "    * Anaconda has most of the libraries you'll need preloaded; but there are times you may need to install a new package.\n",
    "2. Set the random seed (this ensures your work is repeatable)\n",
    "    * For this course, always use 1 as your random seed. If you do not, then your results will differ from the ones used on the marking key and you will loose marks.\n",
    "3. Load data\n",
    "    * This can be from a database, website, file, or other. In this example we will load data from a csv (comma seperated value) file. \n",
    "4. Conduct basic evaluation of the data \n",
    "    * We want to get to know the data in the context of our problem. \n",
    "        * What is our target variable\n",
    "    * What types of data do we have?\n",
    "    * How many features and observations?\n",
    "    * Do we have missing data?\n",
    "    * Do we see evidence of corrupt data?\n",
    "    * For any catagorical variables - are they nominal? ordinal without equal distance or ordinal that can be represented as an interval?\n",
    "5. Process the data\n",
    "    * Conduct pre-split data cleaning\n",
    "    * Split data into training and test sets\n",
    "    * Conduct post-split data cleaning\n",
    "6. Save the data (we'll start modeling it later)\n",
    "    * save the cleaned data to a csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Import and install python libraries\n",
    "\n",
    "Here we import any Python libraries that we plan to use. Any libraries that we import must be installed on your computer. Numpy and Pandas should be installed as part of Anaconda; but if you ever find yourself in a situation where you don't have the library installed, you can use the conda command from a terminal:\n",
    "\n",
    "conda install -c conda-forge <package/library name you want to install>\n",
    "\n",
    "For example:\n",
    "conda install -c conda-forge numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy and pandas libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.0 Set Random Seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's *very* important that you set this! In this course we will use the random seed value of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed to ensure that results are repeatable\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "airbnb = pd.read_csv(\"airbnb.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Conduct initial exploration of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a number of input variables and one target variable. For this analysis, the target variable is price.\n",
    "\n",
    "First, our initial exploration of the data should answer the following questions:\n",
    "1. How many rows and columns\n",
    "2. How much of a problem do we have with na's?\n",
    "3. What types of data are there?\n",
    "4. What types of data are stored in columns\n",
    "    1. identify which variables are numeric and may need to be standardized later\n",
    "    2. identify which variables are categorical and may need to be transformed using and encoders such as one-hot-encoder.\n",
    "5. Identify errors in the data - this is a common problem with categorical vars where the category is mispelled or spelled differently in some instances.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the data\n",
    "airbnb.head(3) # note that we don't want to dump all the data to the screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a basic summary of the data\n",
    "airbnb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a statistical summary of the numeric value in the data\n",
    "airbnb.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are many ways we could explore our data. A rather new library available is called \n",
    "# jupyter-summarytools this library provides functions that provide very thorough summaries \n",
    "# of your data. Though such detail is not always required, there are times when you want a \n",
    "# thorough summary\n",
    "\n",
    "# jupyter-summary tools is not part of the standard anaconda distribution of python, nor \n",
    "# is it in any conda channels. To install this library, you need to install it from the \n",
    "# terminal/command line using pip pip install jupyter-summarytools\n",
    "\n",
    "# once installed, you can import this library and use dfSummary to provide a more thorough \n",
    "# summary of your data\n",
    "#import summarytools\n",
    "#from summarytools import dfSummary\n",
    "#dfSummary(airbnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the missing values by summing the total na's for each variable\n",
    "airbnb.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of these catagorical variables\n",
    "category_var_list = list(airbnb.select_dtypes(include='object').columns)\n",
    "category_var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the categorical variable values - often there are typos here that need to be fixed.\n",
    "for cat in category_var_list: # generally, we want to avoid for loops and use a functional style (i.e. list comprehension)\n",
    "    print(f\"Category: {cat} Values: {airbnb[cat].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary the findings from our initial evaluation of the data\n",
    "\n",
    "* We have 6 categorical variables\n",
    "* We have 3 variables that have missing values\n",
    "* There doesn't seem to be a problem with the catogorical class names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5.0 Process the data\n",
    "\n",
    "* Conduct any data prepartion that should be done *BEFORE* the data split.\n",
    "* Split the data.\n",
    "* Conduct any data preparation that should be done *AFTER* the data split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1  Conduct any data prepartion that should be done *BEFORE* the data split\n",
    "\n",
    "Tasks at this stage include:\n",
    "1. Drop any columns/features \n",
    "2. Decide if you with to exclude any observations (rows) due to missing na's.\n",
    "2. Conduct proper encoding of categorical variables\n",
    "    1. You can transform them using dummy variable encoding, one-hot-encoding, or label encoding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop any columns/variables we will not be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our target is price; but there are three related price variableds - price, price_gte_150, \n",
    "# and price_category. We need to drop price_gte_150, and price_category\n",
    "airbnb.drop(['price_category', 'price_gte_150'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop observations with too many NA's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "If we want to remove the rows with NA's use the following code that is commented out. For this exercise - we will not drop rows with NA's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to remove rows with NA's use the following code:\n",
    "# airbnb.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that there are now no missing values\n",
    "# airbnb.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigage how many rows remain \n",
    "# airbnb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode our categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical variables usually have strings for their values. Many machine learning algorithms do not support string values for the input variables. Therefore, we need to replace these string values with numbers. This process is called categorical variable encoding.\n",
    "\n",
    "In a previous step we identified 5 catagorical variables and found no indication of typos in the class names. Our focus is now on encoding the variables. \n",
    "\n",
    "We have three main approaches to encoding variables (these will be discussed in greater detail in class)\n",
    "* One-Hot-Encoding\n",
    "* Dummy Encoding\n",
    "* Label Encoding\n",
    "\n",
    "In this exercise; we will dummy encode neighbourhood_cleansed, property_type using dummy encoding, and room_type, bed_type and cancelation policy using label encoding. (we will have more discussion on these choices in class)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do our encoding, we must identify if any of our categorical variables have a missing value. We will replace any missing values with the term 'unkown'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb['property_type'].isna().sum() # check for missing values in this variable/column - we can see there are three for this variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb[\"property_type\"].fillna(\"unkown\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb['neighbourhood_cleansed'].isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb['room_type'].isna().sum() # can see by the results below, no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb['bed_type'].isna().sum() # can see by the results below, no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb['cancellation_policy'].isna().sum() # can see by the results below, no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now, let's encode neighborhood_cleansed and property_type as dummy variables and room_type, bed_type and cancelation_policy labeled (numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_df = pd.get_dummies(airbnb['neighbourhood_cleansed'], prefix='neighbourhood_cleansed', drop_first=True)\n",
    "airbnb = airbnb.join(dummies_df)\n",
    "airbnb.drop('neighbourhood_cleansed', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb = airbnb.join(pd.get_dummies(airbnb['property_type'], prefix='property_type', drop_first=True))\n",
    "airbnb.drop('property_type', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "airbnb['room_type'] = labelencoder.fit_transform(airbnb['room_type'])\n",
    "airbnb['bed_type'] = labelencoder.fit_transform(airbnb['bed_type'])\n",
    "airbnb['cancellation_policy'] = labelencoder.fit_transform(airbnb['cancellation_policy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the dataframe columns to verify encoding and dropped columns\n",
    "airbnb.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Split data (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into validation and training set\n",
    "train_df, test_df = train_test_split(airbnb, test_size=0.3)\n",
    "\n",
    "# to reduce repetition in later code, create variables to represent the columns\n",
    "# that are our predictors and target\n",
    "target = 'price'\n",
    "predictors = list(airbnb.columns)\n",
    "predictors.remove(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3  Conduct any data prepartion that should be done *AFTER* the data split\n",
    "\n",
    "We will look at the following:\n",
    "1) imput any missing numeric values using the mean of the variable/column\n",
    "2) remove differences of scale by standardizing the numerica variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols_with_nas = list(train_df.isna().sum()[train_df.isna().sum() > 0].index)\n",
    "numeric_cols_with_nas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the code above that there are 4 variables (columns) that contain missing numeric values (we've already taken care of any missing values in the catagorical variables earlier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "train_df[numeric_cols_with_nas] = imputer.fit_transform(train_df[numeric_cols_with_nas])\n",
    "test_df[numeric_cols_with_nas] = imputer.transform(test_df[numeric_cols_with_nas])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize numeric values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a common scale between the numberic columns by standardizing each numeric column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a standard scaler and fit it to the training set of predictors\n",
    "scaler = preprocessing.StandardScaler()\n",
    "cols_to_stdize = ['latitude', 'longitude', 'accommodates', \n",
    "                   'bathrooms', 'bedrooms', 'beds', 'Number of amenities', \n",
    "                   'guests_included', 'price_per_extra_person', 'minimum_nights', \n",
    "                   'number_of_reviews', 'number_days_btw_first_last_review', \n",
    "                   'review_scores_rating']                \n",
    "               \n",
    "# Transform the predictors of training and validation sets\n",
    "train_df[cols_to_stdize] = scaler.fit_transform(train_df[cols_to_stdize]) # train_predictors is not a numpy array\n",
    "\n",
    "\n",
    "test_df[cols_to_stdize] = scaler.transform(test_df[cols_to_stdize]) # validation_target is now a series object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_df[predictors]\n",
    "train_y = train_df[target] # train_target is now a series objecttrain_df.to_csv('airbnb_train_df.csv', index=False)\n",
    "test_X = train_df[predictors]\n",
    "test_y = test_df[target] # validation_target is now a series object\n",
    "\n",
    "train_df.to_csv('airbnb_train_df.csv', index=False)\n",
    "train_X.to_csv('airbnb_train_X.csv', index=False)\n",
    "train_y.to_csv('airbnb_train_y.csv', index=False)\n",
    "test_df.to_csv('airbnb_test_df.csv', index=False)\n",
    "test_X.to_csv('airbnb_test_X.csv', index=False)\n",
    "test_y.to_csv('airbnb_test_y.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "235px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
