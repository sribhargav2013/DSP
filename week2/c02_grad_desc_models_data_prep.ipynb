{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradiant Descent Modeels - Data Preparation\n",
    "\n",
    "In this notebook we focus on the data loading, basic exploring, and prepatation.\n",
    "\n",
    "This notebook follows closely the previous data cleaning toturial from last week. We will be using the same dataset and producing the same output (not the output from the modified version you would have completed in your exercise)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy and pandas libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "# set random seed to ensure that results are repeatable\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "airbnb = pd.read_csv(\"./data/airbnb.csv\")\n",
    "\n",
    "airbnb.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Conduct initial exploration of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a number of input variables and one target variable. For this analysis, the target variable is price.\n",
    "\n",
    "First, our initial exploration of the data should answer the following questions:\n",
    "1. How many rows and columns\n",
    "2. How much of a problem do we have with na's?\n",
    "3. What types of data are there?\n",
    "4. What types of data are stored in columns\n",
    "    1. identify which variables are numeric and may need to be standardized later\n",
    "    2. identify which variables are categorical and may need to be transformed using and encoders such as one-hot-encoder.\n",
    "5. Identify errors in the data - this is a common problem with categorical vars where the category is mispelled or spelled differently in some instances.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the data\n",
    "airbnb.head(3) # note that we don't want to dump all the data to the screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a basic summary of the data\n",
    "airbnb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a statistical summary of the numeric value in the data\n",
    "airbnb.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are many ways we could explore our data. A rather new library available is called \n",
    "# jupyter-summarytools this library provides functions that provide very thorough summaries \n",
    "# of your data. Though such detail is not always required, there are times when you want a \n",
    "# thorough summary\n",
    "\n",
    "# jupyter-summary tools is not part of the standard anaconda distribution of python, nor \n",
    "# is it in any conda channels. To install this library, you need to install it from the \n",
    "# terminal/command line using pip pip install jupyter-summarytools\n",
    "\n",
    "# once installed, you can import this library and use dfSummary to provide a more thorough \n",
    "# summary of your data\n",
    "import summarytools\n",
    "from summarytools import dfSummary\n",
    "dfSummary(airbnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the missing values by summing the total na's for each variable\n",
    "airbnb.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of these catagorical variables\n",
    "category_var_list = list(airbnb.select_dtypes(include='object').columns)\n",
    "category_var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the categorical variable values - often there are typos here that need to be fixed.\n",
    "for cat in category_var_list: # generally, we want to avoid for loops and use a functional style (i.e. list comprehension)\n",
    "    print(f\"Category: {cat} Values: {airbnb[cat].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary the findings from our initial evaluation of the data\n",
    "\n",
    "* We have 6 categorical variables\n",
    "* We have 3 variables that have missing values\n",
    "* There doesn't seem to be a problem with the catogorical class names."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4.0 Process the data\n",
    "\n",
    "* Conduct any data prepartion that should be done *BEFORE* the data split.\n",
    "* Split the data.\n",
    "* Conduct any data preparation that should be done *AFTER* the data split."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1  Conduct any data prepartion that should be done *BEFORE* the data split\n",
    "\n",
    "Tasks at this stage include:\n",
    "1. Drop any columns/features \n",
    "2. Decide if you with to exclude any observations (rows) due to missing na's.\n",
    "2. Conduct proper encoding of categorical variables\n",
    "    1. You can transform them using dummy variable encoding, one-hot-encoding, or label encoding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop any columns/variables we will not be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our target is price; but there are three related price variableds - price, price_gte_150, \n",
    "# and price_category. We need to drop price_gte_150, and price_category\n",
    "airbnb.drop(['price_category', 'price_gte_150'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop observations with too many NA's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "If we want to remove the rows with NA's use the following code that is commented out. For this exercise - we will not drop rows with NA's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to remove rows with NA's use the following code:\n",
    "# airbnb.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that there are now no missing values\n",
    "# airbnb.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigage how many rows remain \n",
    "# airbnb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode our categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical variables usually have strings for their values. Many machine learning algorithms do not support string values for the input variables. Therefore, we need to replace these string values with numbers. This process is called categorical variable encoding.\n",
    "\n",
    "In a previous step we identified 5 catagorical variables and found no indication of typos in the class names. Our focus is now on encoding the variables. \n",
    "\n",
    "We have three main approaches to encoding variables (these will be discussed in greater detail in class)\n",
    "* One-Hot-Encoding\n",
    "* Dummy Encoding\n",
    "* Label Encoding\n",
    "\n",
    "In this exercise; we will dummy encode neighbourhood_cleansed, property_type using dummy encoding, and room_type, bed_type and cancelation policy using label encoding. (we will have more discussion on these choices in class)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do our encoding, we must identify if any of our categorical variables have a missing value. We will replace any missing values with the term 'unkown'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb['property_type'].isna().sum() # check for missing values in this variable/column - we can see there are three for this variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb[\"property_type\"].fillna(\"unkown\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb['neighbourhood_cleansed'].isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb['room_type'].isna().sum() # can see by the results below, no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb['bed_type'].isna().sum() # can see by the results below, no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb['cancellation_policy'].isna().sum() # can see by the results below, no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now, let's encode neighborhood_cleansed and property_type as dummy variables and room_type, bed_type and cancelation_policy labeled (numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_df = pd.get_dummies(airbnb['neighbourhood_cleansed'], prefix='neighbourhood_cleansed', drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb = airbnb.join(dummies_df)\n",
    "airbnb.drop('neighbourhood_cleansed', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb = airbnb.join(pd.get_dummies(airbnb['property_type'], prefix='property_type', drop_first=True))\n",
    "airbnb.drop('property_type', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "airbnb['room_type'] = labelencoder.fit_transform(airbnb['room_type'])\n",
    "airbnb['bed_type'] = labelencoder.fit_transform(airbnb['bed_type'])\n",
    "airbnb['cancellation_policy'] = labelencoder.fit_transform(airbnb['cancellation_policy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the dataframe columns to verify encoding and dropped columns\n",
    "airbnb.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Split data (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into validation and training set\n",
    "train_df, test_df = train_test_split(airbnb, test_size=0.3)\n",
    "\n",
    "# to reduce repetition in later code, create variables to represent the columns\n",
    "# that are our predictors and target\n",
    "target = 'price'\n",
    "predictors = list(airbnb.columns)\n",
    "predictors.remove(target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3  Conduct any data prepartion that should be done *AFTER* the data split\n",
    "\n",
    "We will look at the following:\n",
    "1) imput any missing numeric values using the mean of the variable/column\n",
    "2) remove differences of scale by standardizing the numerica variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols_with_nas = list(train_df.isna().sum()[train_df.isna().sum() > 0].index)\n",
    "numeric_cols_with_nas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the code above that there are 4 variables (columns) that contain missing numeric values (we've already taken care of any missing values in the catagorical variables earlier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "train_df[numeric_cols_with_nas] = imputer.fit_transform(train_df[numeric_cols_with_nas])\n",
    "test_df[numeric_cols_with_nas] = imputer.transform(test_df[numeric_cols_with_nas])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize numeric values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a common scale between the numberic columns by standardizing each numeric column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a standard scaler and fit it to the training set of predictors\n",
    "scaler = preprocessing.StandardScaler()\n",
    "cols_to_stdize = ['latitude', 'longitude', 'accommodates', \n",
    "                   'bathrooms', 'bedrooms', 'beds', 'Number of amenities', \n",
    "                   'guests_included', 'price_per_extra_person', 'minimum_nights', \n",
    "                   'number_of_reviews', 'number_days_btw_first_last_review', \n",
    "                   'review_scores_rating']                \n",
    "               \n",
    "# Transform the predictors of training and validation sets\n",
    "train_df[cols_to_stdize] = scaler.fit_transform(train_df[cols_to_stdize]) # train_predictors is not a numpy array\n",
    "\n",
    "\n",
    "test_df[cols_to_stdize] = scaler.transform(test_df[cols_to_stdize]) # validation_target is now a series object\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_df[predictors]\n",
    "train_y = train_df[target] # train_target is now a series objecttrain_df.to_csv('airbnb_train_df.csv', index=False)\n",
    "test_X = test_df[predictors]\n",
    "test_y = test_df[target] # validation_target is now a series object\n",
    "\n",
    "train_df.to_csv('./data/airbnb_train_df_price.csv', index=False)\n",
    "train_X.to_csv('./data/airbnb_train_X_price.csv', index=False)\n",
    "train_y.to_csv('./data/airbnb_train_y_price.csv', index=False)\n",
    "test_df.to_csv('./data/airbnb_test_df_price.csv', index=False)\n",
    "test_X.to_csv('./data/airbnb_test_X_price.csv', index=False)\n",
    "test_y.to_csv('./data/airbnb_test_y_price.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (XPython)",
   "language": "python",
   "name": "pythonjvsc74a57bd0b056086e24cb5602cbcb82122035cd3d6ee2ccbf5df29c16e348c108b0f83be3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "235px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "b056086e24cb5602cbcb82122035cd3d6ee2ccbf5df29c16e348c108b0f83be3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
